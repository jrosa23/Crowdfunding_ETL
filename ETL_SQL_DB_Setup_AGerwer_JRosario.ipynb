{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44c71a28-0a5e-43b0-a229-04f7b87a229d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crowdfunding database already exists\n",
      "Existing tables dropped\n",
      "Tables created\n",
      "MongoDB-like schema saved to 'C:\\Users\\asg_a_1p8y6mm\\OneDrive\\Desktop\\WIOA Training\\DataAnalytics\\Module 13\\Module 13; Project 2\\Crowdfunding_ETL\\Resources\\crowdfunding_db_schema.json'\n",
      "Postgres schema saved to 'C:\\Users\\asg_a_1p8y6mm\\OneDrive\\Desktop\\WIOA Training\\DataAnalytics\\Module 13\\Module 13; Project 2\\Crowdfunding_ETL\\Resources\\crowdfunding_db_schema.sql'\n",
      "Category table data:\n",
      "  category_id      category\n",
      "0           1          food\n",
      "1           2         music\n",
      "2           3    technology\n",
      "3           4       theater\n",
      "4           5  film & video\n",
      "5           6    publishing\n",
      "6           7         games\n",
      "7           8   photography\n",
      "8           9    journalism\n",
      "\n",
      "Subcategory table data:\n",
      "   subcategory_id        subcategory\n",
      "0               1        food trucks\n",
      "1               2               rock\n",
      "2               3                web\n",
      "3               4              plays\n",
      "4               5        documentary\n",
      "5               6     electric music\n",
      "6               7              drama\n",
      "7               8         indie rock\n",
      "8               9          wearables\n",
      "9              10         nonfiction\n",
      "10             11          animation\n",
      "11             12        video games\n",
      "12             13             shorts\n",
      "13             14            fiction\n",
      "14             15  photography books\n",
      "15             16   radio & podcasts\n",
      "16             17              metal\n",
      "17             18               jazz\n",
      "18             19       translations\n",
      "19             20         television\n",
      "20             21       mobile games\n",
      "21             22        world music\n",
      "22             23    science fiction\n",
      "23             24              audio\n",
      "\n",
      "Contacts table data:\n",
      "     contact_id    first_name   last_name  \\\n",
      "0          4661       Cecilia     Velasco   \n",
      "1          3765       Mariana       Ellis   \n",
      "2          4187         Sofie       Woods   \n",
      "3          4941      Jeanette    Iannotti   \n",
      "4          2199        Samuel     Sorgatz   \n",
      "..          ...           ...         ...   \n",
      "995        3684       Whitney       Noack   \n",
      "996        5784     Gelsomina  Migliaccio   \n",
      "997        1498   Evangelista     Pereira   \n",
      "998        6073        Gareth     Comolli   \n",
      "999        4939  Michelangelo        Hess   \n",
      "\n",
      "                                         email  \n",
      "0                 cecilia.velasco@rodrigues.fr  \n",
      "1                      mariana.ellis@rossi.org  \n",
      "2                      sofie.woods@riviere.com  \n",
      "3                  jeanette.iannotti@yahoo.com  \n",
      "4                     samuel.sorgatz@gmail.com  \n",
      "..                                         ...  \n",
      "995             whitney.noack@laboratorios.org  \n",
      "996              gelsomina.migliaccio@junk.com  \n",
      "997  evangelista.pereira@thompson-peterson.biz  \n",
      "998                  gareth.comolli@tiscali.fr  \n",
      "999              michelangelo.hess@bouygtel.fr  \n",
      "\n",
      "[1000 rows x 4 columns]\n",
      "\n",
      "Campaign table data:\n",
      "     cf_id  contact_id                  company_name  \\\n",
      "0      147        4661    Baldwin, Riley and Jackson   \n",
      "1     1621        3765                      Odom Inc   \n",
      "2     1812        4187    Melton, Robinson and Fritz   \n",
      "3     2156        4941   Mcdonald, Gonzalez and Ross   \n",
      "4     1365        2199                 Larson-Little   \n",
      "..     ...         ...                           ...   \n",
      "995   2986        3684              Manning-Hamilton   \n",
      "996   2031        5784                    Butler LLC   \n",
      "997   1627        1498                      Ball LLC   \n",
      "998   2175        6073   Taylor, Santiago and Flores   \n",
      "999   1788        4939  Hernandez, Norton and Kelley   \n",
      "\n",
      "                                       description      goal   pledged  \\\n",
      "0             Pre-emptive tertiary standardization     100.0       0.0   \n",
      "1                 Managed bottom-line architecture    1400.0   14560.0   \n",
      "2     Function-based leadingedge pricing structure  108400.0  142523.0   \n",
      "3    Vision-oriented fresh-thinking conglomeration    4200.0    2477.0   \n",
      "4                        Proactive foreground core    7600.0    5265.0   \n",
      "..                                             ...       ...       ...   \n",
      "995            Vision-oriented scalable definition   97300.0  153216.0   \n",
      "996       Future-proofed upward-trending migration    6600.0    4814.0   \n",
      "997              Right-sized full-range throughput    7600.0    4603.0   \n",
      "998           Polarized composite customer loyalty   66600.0   37823.0   \n",
      "999                    Expanded eco-centric policy  111100.0   62819.0   \n",
      "\n",
      "        outcome  backers_count country currency launched_date    end_date  \\\n",
      "0        failed              0      CA      CAD    2020-02-13  2021-03-01   \n",
      "1    successful            158      US      USD    2021-01-25  2021-05-25   \n",
      "2    successful           1425      AU      AUD    2020-12-17  2021-12-30   \n",
      "3        failed             24      US      USD    2021-10-21  2022-01-17   \n",
      "4        failed             53      US      USD    2020-12-21  2021-08-23   \n",
      "..          ...            ...     ...      ...           ...         ...   \n",
      "995  successful           2043      US      USD    2020-12-29  2021-05-30   \n",
      "996      failed            112      US      USD    2021-10-15  2021-11-30   \n",
      "997    canceled            139      IT      EUR    2021-11-06  2021-12-10   \n",
      "998      failed            374      US      USD    2020-10-08  2021-04-11   \n",
      "999    canceled           1122      US      USD    2020-12-30  2021-08-18   \n",
      "\n",
      "    category_id subcategory_id  \n",
      "0          None           None  \n",
      "1             2              2  \n",
      "2             3              3  \n",
      "3             2              2  \n",
      "4             4              4  \n",
      "..          ...            ...  \n",
      "995        None           None  \n",
      "996           4              4  \n",
      "997           4              4  \n",
      "998           2              8  \n",
      "999        None           None  \n",
      "\n",
      "[1000 rows x 14 columns]\n",
      "Tables in the database:  ['contacts', 'campaign', 'category', 'subcategory']\n"
     ]
    }
   ],
   "source": [
    "# Install psycopg2 if not already installed. You can do this in your\n",
    "# terminal or command prompt:\n",
    "# pip install psycopg2-binary\n",
    "\n",
    "# SQL database setup\n",
    "import sqlalchemy\n",
    "import pandas as pd\n",
    "import os\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import MetaData, Table, Column, String, Integer, Float, Boolean, Date, ForeignKey\n",
    "from sqlalchemy import inspect\n",
    "from sqlalchemy import exc\n",
    "import json\n",
    "\n",
    "# Define the target directory\n",
    "target_dir = r\"C:\\Users\\asg_a_1p8y6mm\\OneDrive\\Desktop\\WIOA Training\\DataAnalytics\\Module 13\\Module 13; Project 2\\Crowdfunding_ETL\\Resources\"\n",
    "\n",
    "# Create the target directory if it doesn't exist\n",
    "os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "# Create the database engine using a variable for the db connection string\n",
    "db_string = f\"postgresql://postgres:postgres@127.0.0.1:5432/crowdfunding_db\"\n",
    "engine_default = create_engine(db_string)\n",
    "\n",
    "\n",
    "# ### Import the CSV files into DataFrames\n",
    "category_df = pd.read_csv(os.path.join(target_dir, 'category.csv'))\n",
    "subcategory_df = pd.read_csv(os.path.join(target_dir, 'subcategory.csv'))\n",
    "contacts_df = pd.read_csv(os.path.join(target_dir, 'contacts.csv'))\n",
    "campaign_df = pd.read_csv(os.path.join(target_dir, 'campaign.csv'))\n",
    "\n",
    "\n",
    "# ### Create the crowdfunding_db database\n",
    "try:\n",
    "    conn = engine_default.connect()\n",
    "    result = conn.execute(sqlalchemy.text(\n",
    "        \"SELECT 1 FROM pg_database WHERE datname='crowdfunding_db';\"\n",
    "    )).fetchone()\n",
    "\n",
    "    if result is None:  # No existing database\n",
    "        conn.execution_options(isolation_level=\"AUTOCOMMIT\").execute(sqlalchemy.text(\"CREATE DATABASE crowdfunding_db;\"))\n",
    "        print(\"New crowdfunding database created\")\n",
    "    else:\n",
    "        print(\"Crowdfunding database already exists\")  # Database\n",
    "    conn.close()\n",
    "except Exception as e:\n",
    "    print(f\"Error connecting to or creating database: {e}\")\n",
    "\n",
    "# Re-create engine to connect to the new database\n",
    "engine = create_engine(db_string)\n",
    "conn = engine.connect()\n",
    "\n",
    "# Create Metadata object\n",
    "metadata = MetaData()\n",
    "\n",
    "# Define the tables\n",
    "category_table = Table('category', metadata,\n",
    "    Column('category_id', String, primary_key=True),\n",
    "    Column('category', String)\n",
    ")\n",
    "\n",
    "subcategory_table = Table('subcategory', metadata,\n",
    "    Column('subcategory_id', String, primary_key=True),\n",
    "    Column('subcategory', String)\n",
    ")\n",
    "\n",
    "contacts_table = Table('contacts', metadata,\n",
    "    Column('contact_id', Integer, primary_key=True),\n",
    "    Column('first_name', String),\n",
    "    Column('last_name', String),\n",
    "    Column('email', String)\n",
    ")\n",
    "\n",
    "campaign_table = Table('campaign', metadata,\n",
    "    Column('cf_id', Integer, primary_key=True),\n",
    "    Column('contact_id', Integer, ForeignKey('contacts.contact_id')),\n",
    "    Column('company_name', String),\n",
    "    Column('description', String),\n",
    "    Column('goal', Float),\n",
    "    Column('pledged', Float),\n",
    "    Column('outcome', String),\n",
    "    Column('backers_count', Integer),\n",
    "    Column('country', String),\n",
    "    Column('currency', String),\n",
    "    Column('launched_date', Date),\n",
    "    Column('end_date', Date),\n",
    "    Column('category_id', String, ForeignKey('category.category_id')),\n",
    "    Column('subcategory_id', String, ForeignKey('subcategory.subcategory_id'))\n",
    ")\n",
    "\n",
    "# Create all database tables, *replacing* existing ones\n",
    "# If replacing the tables, drop them in reverse order of dependencies first, before creating\n",
    "try:\n",
    "    metadata.drop_all(engine)\n",
    "    print(\"Existing tables dropped\")\n",
    "except exc.OperationalError as e:\n",
    "    print(f\"Tables didn't exist: {e}\")\n",
    "metadata.create_all(engine)\n",
    "print(\"Tables created\")\n",
    "\n",
    "def infer_mongodb_schema(df):\n",
    "    \"\"\"\n",
    "    Infers a MongoDB-like schema from a Pandas DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame to inspect.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary representing the inferred schema.\n",
    "    \"\"\"\n",
    "    schema = {}\n",
    "    for col in df.columns:\n",
    "        col_type = str(df[col].dtype)\n",
    "        \n",
    "        # Attempt to infer sub-type based on first non-null element\n",
    "        sample_value = df[col].dropna().iloc[0] if not df[col].dropna().empty else None\n",
    "        subtype = None\n",
    "        if sample_value is not None:\n",
    "           if isinstance(sample_value, str):\n",
    "               try:\n",
    "                   pd.to_datetime(sample_value)\n",
    "                   subtype = \"date\"\n",
    "               except:\n",
    "                   pass \n",
    "        \n",
    "        if col_type.startswith('int'):\n",
    "            col_type = \"int\"\n",
    "        elif col_type.startswith('float'):\n",
    "            col_type = \"float\"\n",
    "        elif col_type.startswith('date'):\n",
    "          col_type = \"date\"\n",
    "        else:\n",
    "            col_type = \"string\"\n",
    "\n",
    "        # Use subtype if one was found\n",
    "        if subtype:\n",
    "           schema[col] = {\"type\": subtype}\n",
    "        else:\n",
    "           schema[col] = {\"type\": col_type}\n",
    "\n",
    "    return schema\n",
    "\n",
    "def generate_mongodb_schemas(category_df, subcategory_df, contacts_df, campaign_cleaned):\n",
    "    \"\"\"\n",
    "    Generates MongoDB schemas for all the dataframes\n",
    "\n",
    "    Args:\n",
    "       category_df (pd.DataFrame): Category DataFrame to inspect\n",
    "       subcategory_df (pd.DataFrame): Subcategory DataFrame to inspect\n",
    "       contacts_df (pd.DataFrame): Contacts DataFrame to inspect\n",
    "       campaign_cleaned (pd.DataFrame): Cleaned Campaign DataFrame to inspect\n",
    "    Returns:\n",
    "        dict: A dictionary that holds each of the dataframes schemas\n",
    "    \"\"\"\n",
    "    schemas = {}\n",
    "    schemas['category_schema'] = infer_mongodb_schema(category_df)\n",
    "    schemas['subcategory_schema'] = infer_mongodb_schema(subcategory_df)\n",
    "    schemas['contacts_schema'] = infer_mongodb_schema(contacts_df)\n",
    "    schemas['campaign_schema'] = infer_mongodb_schema(campaign_cleaned)\n",
    "    return schemas\n",
    "\n",
    "campaign_cleaned = campaign_df.copy()\n",
    "campaign_cleaned = campaign_cleaned.rename(columns={\"blurb\": \"description\"})\n",
    "\n",
    "# Correctly dropping columns\n",
    "columns_to_drop = ['category', 'sub-category', 'category_x','category_y', 'subcategory', 'category & sub-category', 'sub-category']\n",
    "campaign_cleaned = campaign_cleaned.drop(columns=[col for col in columns_to_drop if col in campaign_cleaned.columns])\n",
    "\n",
    "# Keep only necessary columns\n",
    "campaign_cleaned = campaign_cleaned[['cf_id', 'contact_id', 'company_name', 'description', 'goal', 'pledged', 'outcome',\n",
    "                                    'backers_count', 'country', 'currency', 'launched_date', 'end_date',\n",
    "                                    'category_id', 'subcategory_id']]\n",
    "# Map category_id to match those in the category table\n",
    "category_mapping = {\n",
    "    'catl': '1',\n",
    "    'cat2': '2',\n",
    "    'cat3': '3',\n",
    "    'cat4': '4',\n",
    "    'cat5': '5',\n",
    "    'cat6': '6',\n",
    "    'cat7': '7',\n",
    "    'cat8': '8',\n",
    "    'cat9': '9'\n",
    "}\n",
    "campaign_cleaned['category_id'] = campaign_cleaned['category_id'].map(category_mapping)\n",
    "\n",
    "# Map subcategory_id to match those in the subcategory table\n",
    "subcategory_mapping = {\n",
    "    'subcatl': '1',\n",
    "    'subcat2': '2',\n",
    "    'subcat3': '3',\n",
    "    'subcat4': '4',\n",
    "    'subcat5': '5',\n",
    "    'subcat6': '6',\n",
    "    'subcat7': '7',\n",
    "    'subcat8': '8',\n",
    "    'subcat9': '9',\n",
    "    'subcat10': '10',\n",
    "    'subcat11': '11',\n",
    "    'subcat12': '12',\n",
    "    'subcat13': '13',\n",
    "    'subcat14': '14',\n",
    "    'subcat15': '15',\n",
    "    'subcat16': '16',\n",
    "    'subcat17': '17',\n",
    "    'subcat18': '18',\n",
    "    'subcat19': '19',\n",
    "    'subcat20': '20',\n",
    "    'subcat21': '21',\n",
    "    'subcat22': '22',\n",
    "    'subcat23': '23',\n",
    "    'subcat24': '24'\n",
    "}\n",
    "campaign_cleaned['subcategory_id'] = campaign_cleaned['subcategory_id'].map(subcategory_mapping)\n",
    "\n",
    "# Convert launched_date and end_date to date without specifying unit\n",
    "campaign_cleaned[\"launched_date\"] = pd.to_datetime(campaign_cleaned[\"launched_date\"]).dt.date\n",
    "campaign_cleaned[\"end_date\"] = pd.to_datetime(campaign_cleaned[\"end_date\"]).dt.date\n",
    "\n",
    "# Generate schemas\n",
    "schemas = generate_mongodb_schemas(category_df, subcategory_df, contacts_df, campaign_cleaned)\n",
    "\n",
    "# Save the MongoDB-like schema to a JSON file in the target directory\n",
    "json_filepath = os.path.join(target_dir, 'crowdfunding_db_schema.json')\n",
    "with open(json_filepath, 'w') as f:\n",
    "    json.dump(schemas, f, indent=4)\n",
    "print(f\"MongoDB-like schema saved to '{json_filepath}'\")\n",
    "\n",
    "# Save the Postgres schema to a SQL file in the target directory\n",
    "sql_filepath = os.path.join(target_dir, 'crowdfunding_db_schema.sql')\n",
    "with open(sql_filepath, 'w') as f:\n",
    "    for table in metadata.sorted_tables:\n",
    "        f.write(str(sqlalchemy.schema.CreateTable(table).compile(engine)) + \";\\n\")\n",
    "print(f\"Postgres schema saved to '{sql_filepath}'\")\n",
    "\n",
    "# Import the DataFrames\n",
    "category_df.to_sql('category', con=conn, if_exists='append', index=False)\n",
    "subcategory_df.to_sql('subcategory', con=conn, if_exists='append', index=False)\n",
    "contacts_df.to_sql('contacts', con=conn, if_exists='append', index=False)\n",
    "\n",
    "# Verify that the data was imported correctly\n",
    "print(\"Category table data:\")\n",
    "print(pd.read_sql_query(\"SELECT * FROM category\", engine))\n",
    "print(\"\\nSubcategory table data:\")\n",
    "print(pd.read_sql_query(\"SELECT * FROM subcategory\", engine))\n",
    "print(\"\\nContacts table data:\")\n",
    "print(pd.read_sql_query(\"SELECT * FROM contacts\", engine))\n",
    "\n",
    "\n",
    "# Import the cleaned DataFrame into the campaign table\n",
    "try:\n",
    "    campaign_cleaned.to_sql('campaign', con=conn, if_exists='append', index=False)\n",
    "    print(\"\\nCampaign table data:\")\n",
    "    print(pd.read_sql_query(\"SELECT * FROM campaign\", engine))\n",
    "except Exception as e:\n",
    "    print(f\"Error importing campaign data: {e}\")\n",
    "\n",
    "conn.close()\n",
    "\n",
    "# Verify that the tables were created\n",
    "inspector = inspect(engine)\n",
    "print(\"Tables in the database: \", inspector.get_table_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a309c78-e01e-461c-a002-51644ea73bcb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
